{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d03b4947",
   "metadata": {},
   "source": [
    "# Installing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f80e6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\OneDrive\\Desktop\\work\\llm_hackathon\\.venv\\Scripts\\python.exe: No module named pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2789323",
   "metadata": {},
   "source": [
    "# Importing relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a945b177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import ToolMessage\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "import getpass\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.tools.render import render_text_description # to describe tools as a string \n",
    "from langchain_core.output_parsers import JsonOutputParser # ensure JSON input for tools\n",
    "from operator import itemgetter # to retrieve specific items in our chain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814fb692",
   "metadata": {},
   "source": [
    "# Setting up tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c85c5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, AllChem, Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from enum import Enum\n",
    "from typing import Annotated\n",
    "\n",
    "# --- Define tools ---\n",
    "class MultiplyInput(BaseModel):\n",
    "    a: int = Field(..., description=\"first integer\")\n",
    "    b: int = Field(..., description=\"second integer\")\n",
    "\n",
    "@tool(\"multiply\", args_schema=MultiplyInput)\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a with b\"\"\"\n",
    "    return a * b\n",
    "\n",
    "class AddInput(BaseModel):\n",
    "    x: int = Field(..., description=\"first integer\")\n",
    "    y: int = Field(..., description=\"second integer\")\n",
    "\n",
    "@tool(\"add\", args_schema=AddInput)\n",
    "def add(x: int, y: int) -> int:\n",
    "    \"\"\"Add x and y\"\"\"\n",
    "    return x + y\n",
    "\n",
    "@tool\n",
    "def converse(input: str) -> str:\n",
    "    \"Provide a natural language response using the user input.\"\n",
    "    return llm.invoke(input)\n",
    "\n",
    "# Pydantic stuff i dont like this >.<\n",
    "DESC_MAP = {name: fn for name, fn in Descriptors.descList}\n",
    "DESC_NAMES = sorted(DESC_MAP.keys())\n",
    "\n",
    "class DescriptorArgs(BaseModel):\n",
    "    smiles: str = Field(..., description=\"SMILES string of the molecule.\")\n",
    "\n",
    "    # Pylance sees 'str', but the LLM will see an enum in the schema\n",
    "    descriptor: Annotated[\n",
    "        str,\n",
    "        Field(\n",
    "            description=f\"RDKit descriptor name. One of: {', '.join(DESC_NAMES[:50])} … (total {len(DESC_NAMES)})\",\n",
    "            json_schema_extra={\"enum\": DESC_NAMES},\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # Runtime validation (and optional case-insensitive normalization)\n",
    "    @field_validator(\"descriptor\")\n",
    "    @classmethod\n",
    "    def validate_descriptor(cls, v: str) -> str:\n",
    "        v2 = v.strip()\n",
    "        if v2 in DESC_MAP:\n",
    "            return v2\n",
    "        # case-insensitive fallback\n",
    "        matches = [n for n in DESC_MAP if n.lower() == v2.lower()]\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "        raise ValueError(f\"Invalid descriptor '{v}'. Choose one of: {', '.join(DESC_NAMES[:20])} …\")\n",
    "\n",
    "# TOOLS \n",
    "@tool(args_schema=DescriptorArgs)\n",
    "def descriptor_calculation(smiles: str, descriptor: str) -> str:\n",
    "    \"\"\"Calculate molecular descriptors from a SMILES string.\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return \"Invalid SMILES string\"\n",
    "    \n",
    "    desc = {desc_name: func(mol) for desc_name, func in Descriptors.descList}\n",
    "    return desc[descriptor]\n",
    "    \n",
    "@tool#(args_schema=DescriptorArgs)\n",
    "def MolToSmiles(molecule: str) -> str:\n",
    "    \"\"\"Validate and canonicalize a SMILES string.\"\"\"\n",
    "    candidate = molecule.strip()\n",
    "    mol = Chem.MolFromSmiles(candidate)\n",
    "    \n",
    "    if mol is None:\n",
    "        raise ValueError(f\"Invalid SMILES: {candidate}\")\n",
    "    return Chem.MolToSmiles(mol, canonical=True)\n",
    "\n",
    "\n",
    "@tool\n",
    "def partial_charge_calculation(smiles: str) -> str:\n",
    "    \"\"\"Calculate Gasteiger partial charges from a SMILES string.\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return \"Invalid SMILES string\"\n",
    "\n",
    "    AllChem.Mol.ComputeGasteigerCharges(mol)\n",
    "    charges = [atom.GetProp('_GasteigerCharge') for atom in mol.GetAtoms()]\n",
    "    return str(charges)\n",
    "\n",
    "\n",
    "@tool\n",
    "def generate_png_descriptors(smiles: str) -> str:\n",
    "    \"\"\"Generate a 2D depiction of the molecule with descriptors annotated.\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return \"Invalid SMILES string\"\n",
    "    \n",
    "    AllChem.Mol.ComputeGasteigerCharges(mol)\n",
    "    contribs = [mol.GetAtomWithIdx(i).GetDoubleProp('_GasteigerCharge') for i in range(mol.GetNumAtoms())]\n",
    "    d2d = Draw.MolDraw2DCairo(400, 400)\n",
    "    sim = SimilarityMaps.GetSimilarityMapFromWeights(mol, contribs, d2d, colorMap='jet', contourLines=10)\n",
    "    sim.FinishDrawing()\n",
    "    sim.WriteDrawingText('molecule.png')\n",
    "\n",
    "    return \"molecule.png\"\n",
    "\n",
    "@tool\n",
    "def display_image(file_path: str) -> str:\n",
    "    \"\"\"Display the image from the file path.\"\"\"\n",
    "    from PIL import Image\n",
    "    img = Image.open(file_path)\n",
    "    img.show()\n",
    "    return \"Image displayed\"\n",
    "\n",
    "\n",
    "\n",
    "tools = [multiply, add, partial_charge_calculation, generate_png_descriptors, descriptor_calculation]\n",
    "\n",
    "tools_by_name: dict[str, any] = {t.name: t for t in tools}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc1ffb6",
   "metadata": {},
   "source": [
    "# setting up the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec788b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'descriptor_calculation', 'arguments': {'smiles': 'C1=CC=C(C(=C1)C(=O)O)C(=O)O', 'descriptor': 'TPSA'}}\n",
      "{'name': 'final', 'arguments': {}, 'final_answer': 74.6}\n",
      "what is the TPSA value for benzoic acid\n",
      "74.6\n"
     ]
    }
   ],
   "source": [
    "#config\n",
    "#if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "#  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "#google_api_key = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "#if not google_api_key:\n",
    "#    raise ValueError(\"GOOGLE_API_KEY environment variable not set. Please set it in the .env file or your environment.\")\n",
    "\n",
    "def tool_chain(model_output):\n",
    "    print([x for x in model_output])\n",
    "    tool_map = {tool.name: tool for tool in tools}\n",
    "    chosen_tool = tool_map[model_output[\"name\"]]\n",
    "    return itemgetter(\"arguments\") | chosen_tool\n",
    "\n",
    "llm = OllamaLLM(model=\"llama3.1:8b\")\n",
    "query = input(\"Input: \")\n",
    "\n",
    "rendered_tools = render_text_description(tools)\n",
    "system_prompt = f\"\"\"You are an assistant that has access to the following set of tools.\n",
    "Here are the names and descriptions for each tool:\n",
    "\n",
    "{rendered_tools}\n",
    "Given the user input, return the name and input of the tool to use.\n",
    "Return your response as a JSON blob with 'name' and 'arguments' keys.\n",
    "The value associated with the 'arguments' key should be a dictionary of parameters.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_prompt), (\"user\", \"{input}\")]\n",
    ")\n",
    "\n",
    "chain = prompt | llm | JsonOutputParser() | tool_chain # pipeline the prompt into llm's template then pass the output to json parser then pass it to tool_chain\n",
    "\n",
    "multi_system_prompt = f\"\"\"You have these tools:\n",
    "\n",
    "{rendered_tools}\n",
    "\n",
    "You will solve the user's task by choosing tools only as ABSOLUTELY neccessary and arguments. If you have enough information to answer the user's question after a tool call, do not call any more tools.\n",
    "Return ONLY JSON with keys:\n",
    "- \"name\": tool name to call next, or \"final\" to finish\n",
    "- \"arguments\": dict of arguments for that tool (omit if name == \"final\")\n",
    "- \"final_answer\": present ONLY if name == \"final\"\n",
    "\n",
    "Use prior tool results (provided in the scratchpad) to decide the next step.\n",
    "\"\"\"\n",
    "\n",
    "multi_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", multi_system_prompt),\n",
    "        (\"user\", \"{input}\"),\n",
    "        (\"assistant\", \"{scratchpad}\"), \n",
    "    ]\n",
    ")\n",
    "\n",
    "multi_chain = multi_prompt | llm | JsonOutputParser()\n",
    "\n",
    "def run_multi_step(user_query: str, max_steps: int = 128):\n",
    "    scratchpad = \"\"\n",
    "    for _ in range(max_steps):\n",
    "        msg = multi_chain.invoke({\"input\": user_query, \"scratchpad\": scratchpad})\n",
    "        step = multi_chain.invoke({\"input\": user_query, \"scratchpad\": scratchpad})\n",
    "        name = step[\"name\"]\n",
    "        print(step)\n",
    "        if name == \"final\":\n",
    "            return step.get(\"final_answer\", \"(no final answer)\")\n",
    "        if name not in tools_by_name:\n",
    "            raise ValueError(f\"Unknown tool: {name}\")\n",
    "        args = step.get(\"arguments\", {}) or {}\n",
    "        tool_result = tools_by_name[name].invoke(args)\n",
    "        scratchpad += f\"\\nTOOL={name} ARGS={args} RESULT={tool_result}\"\n",
    "    raise RuntimeError(\"Max steps reached without final answer\")\n",
    "\n",
    "final_answer = run_multi_step(query)\n",
    "print(query)\n",
    "print(final_answer)\n",
    "\n",
    "#chain = llm\n",
    "#chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b690922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
